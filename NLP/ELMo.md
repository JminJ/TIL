# ELMo #
------
> **Word2Vec, GloVe**
>> Bank라는 단어는 '은행'이라는 뜻과 '둑'이라는 의미를 지니고 있다. 하지만 기존 임베딩 방법이였던 Word2Vec, GloVe는 단어를 문장의 맥락과 상관 없이 즉, 뜻과 상관 없이 철자만 같다면 같은 임베딩 벡터를 뱉어낸다.
>> 이렇게 자칫 성능을 떨어뜨릴 수 있는 요소를 보완하기 위해 단어를 임베딩 하기 전 전체 문장을 고려해서 임베딩을 하는 것이 `문맥을 반영한 워드 임베딩(Contextualized Word Embedding)`이다.

## biLM(Bidirectional Language Model)의 사전 훈련 ##

ELMo는 양쪽 방향의 언어 모델을 둘 다 활용한다고 해 biLM이라고 한다. biLM은 각각 forward, backward의 단 방향 언어 모델을 가지고 있다. 

<img src = '/image\2021_02_18_16.png' width = '65%'>

이는 일반적인 양방향 RNN과는 다른데, 일반적인 양방향 RNN은 forward, backward 단 방향 RNN의 은닉 상태를 다음 층의 입력으로 보내기 전에 연결(concatenate)시킨다. 하지만 biLM은 forward, backward 언어 모델이 `각각의 은닉 상태만을 다음 은닉층으로 보내며 훈련시킨 후에 ELMo 표현으로 사용하기 위해서 은닉 상태를 연결(concatenate)`시킨다.

## biLM의 활용 ##

biLM이 훈련되었다면, ELMo가 사전 훈련된 biLM을 통해 입력 문장으로부터 단어를 임베딩하는 과정을 보겠다. 

<img src = '/image\2021_02_18_17.png' width = '65%'>

play라는 단어가 임베딩 되고 있다고 한다면, play라는 단어를 임베딩하기 위해서 ELMo는 위 그림의 사각형 부분의 각 층의 결과값들을 재료로 사용한다. `즉 해당 시점의 biLM의 각 층의 출력값을 가져온다.` 순방향 언어 모델과 역방향 언어 모델의 각 층의 출력값을 연결(concatenate) 시키고 추가 작업을 진행한다.

각 층의 출력값이란 첫 번째는 임베딩 층을 의미하며, 나머지 층은 각 층의 은닉 상태를 뜻한다. 각 층의 출력값이 가진 정보는 전부 서로 다른 종류의 정보를 가지고 있을 것이므로, 이들을 모두 활용한다는 것이 ELMo의 직관적인 아이디어이다. 아래에 ELMo가 임베딩 벡터를 얻는 과정을 보여준다.

### 1) 각 층의 출력값을 연결한다. ###

<img src = '/image\2021_02_18_18.png' >

### 2) 각 층의 출력값 별로 가중치를 준다. ###

<img src = '/image\2021_02_18_19.png'>

### 3) 각 층의 출력값을 모두 더한다. ###

<img src = '/image\2021_02_18_20.png'>

여기서 2번과 3번을 합쳐 가중합(Weighted Sum)을 한다고 할 수 있다.

### 4) 벡터의 크기를 결정하는 스칼라 매개변수를 곱한다. ###

<img src = '/image\2021_02_18_21.png'>

이렇게 완성된 벡터를 ELMo 표현이라고 한다. 여기까지는 ELMo를 얻는 과정이였고 ELMo를 입력으로 사용하고 수행하고 싶은 과제를 위해 이 표현을 사용할 수 있을 것이다.

ELMo 표현은 기존의 임베딩 벡터와 함께 사용할 수 있다. 예를들어 텍스트 분류 작업을 위해 GloVe와 같은 기존의 방법론을 사용한 임베딩 벡터가 있다고 하자. 이 때, GloVe와 ELMo를 연결(concatenage)해 입력으로 사용할 수 있다. **이 때, ELMo 표현을 만드는데 사용되는 사전 훈련된 언어 모델의 가중치는 고정시킨다. 그리고 대신 위에서 사용한 s1, s2, s3와 γ는 훈련 과정에서 학습된다.**

<img src = '/image\2021_02_18_22.png'>

위의 그림에서 ELMo 표현이 기존의 GloVe 등과 같은 임베딩 벡터와 함께 NLP 태스크의 입력이 되는 것을 보여준다.

----------
### 출처 ###
* <https://wikidocs.net/33930>