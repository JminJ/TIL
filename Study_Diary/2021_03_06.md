# 공부한 것 #
-----
### pytorch ###
* torch.cat 정리
### fastcampus ###
* seq2seq-attention 코드 학습
* gradient accumulation

-----
### Link ###
* <https://www.notion.so/torch-cat-b0397a1060f44e689966adfbe7c53dfd>
* <https://www.notion.so/Gradient-Accumulation-2ce002fd85904a8e92004e6f0c58dee1>