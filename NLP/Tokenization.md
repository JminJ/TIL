# Tokenization #
---------------------------

## Tokenization? ##
NLP에서 문장을 학습시키기 위해서는 전처리가 필수적이다. 물론 정규식을 사용하여 문장에 불필요한 문자를 제거하고 필요한 문자만 남기는 방식 또한 전처리 과정이지만 사실 이 이전에 문장 단위로 끊어주는 Sentence segmentation(Sentence Tokenization)이 필요할 때가 있다.

그래서 Tokenization 중 Sentence Tokenization을 먼저 알아보겠다. 쉽게 생각하면 문장의 '.'을 기준으로 끊어 주면 되지만 "나는 어제 M.J에게 문자를 보냈다."와 같이 문장 중간 중간에 '.'이 있는 문장의 경우 우리가 원했던 방향과 조금 다른 결과가 만들어질 수가 있다.

따라서 직접 tokenization하기보다 nltk와 같은 라이브러리들이 지원하는 tokenizer를 사용하는 것을 권장한다.(하지만 이들도 완벽히 처리를 할 수는 없다..)

| *NLTK : sent_tokenize*
```python
from nltk.tokenize import sent_tokenize

text = '안녕하세요, 저는 JmJ라고 합니다. 요즘 자연어 처리에 관심을 가져 공부하고 있습니다~!'
new_text_list = sent_tokenize(text)

print(new_text_list)
```
## Korean Tokenization ##
물론 방금 예시를 한국어로 만들어봤지만 영어보다 한국어를 Tokenization하는 것은 꽤나 까다로운 일이다. ***우선 한국어는 교착어이다***. 영어와 다르게 조사를 붙여 뜻을 달리한다. '그가', '그는', '그에게' 등 조사를 통해 무궁무진한 뜻의 변화가 일어난다. 자연어 처리 중 같은 단어에 서로 다른 조사가 붙어 다른 단어로 인식이 되는 경우가 있어 매우 힘들고 어려워진다. 

따라서 한국어는 조사를 분리해 주어야 한다. 이 때 한국어의 **형태소**라는 개념이 매우 중요하다. 형태소는 뜻을 가진 가장 작은 말의 단위를 말한다. 형태소는 두 가지 형태로 쪼개지는데, 자립 형태소와 의존 형태소이다. 형태소 토큰화를 통해서 우리는 영어에서의 단어 토큰화와 유사한 형태를 얻을 수 있을 것이다.

> **자립 형태소, 의존 형태소**
> * 자립 형태소 : 접사, 어미, 조사와 상관없이 자립하여 사용할 수 있는 형태소.
> * 의존 형태소 : 다른 형태소와 결합하여 사용되는 형태소. 접사, 어미, 조사, 어간을 말한다. 

두 번째 이유는 **띄어쓰기가 영어보다 잘 지켜지지 않는다는 점**이다. 띄어쓰기가 한국어에 적용되 보편화 된것은 1933년대 부터이다. 즉 우리와 띄어쓰기가 함께한 역사가 그리 길지 않다는 것이다. 또한 한국어는 띄어쓰기가 없어도 이해가 가능한 언어이다. 이 점들이 띄어쓰기를 틀리거나 잘 지켜지지 않게 만들어 자연어 처리가 어려워졌다.

## Part-of-speech tagging ##
Part-of-speech tagging(품사 태깅)은 표기는 같으나 품사에 따라 뜻이 달라지는 단어들의 의미를 제대로 파악하기 위해 문장에서 해당 단어가 어떤 품사로 쓰였는지 보는 것이다. Tokenization 과정에서 각 단어가 어떤 품사로 쓰였는지 구분해주기도 하는데, 이 작업을 품사 태깅이라고 부른다.

***Use Konlpy_Okt***
```python
from konlpy.tag import Okt

okt = Okt()
print(okt.pos(text))
```
***Use Konlpy_Kkma***
```python
from konlpy.tag import Kkma

kkma = Kkma()
print(kkma.pos(text))
```

--------------------------
### 출처 ###
* <https://wikidocs.net/21698>
